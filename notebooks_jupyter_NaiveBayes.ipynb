{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.functions import col, lit, udf\n",
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file paths\n",
    "labelsPath=\"gs://bigdataween-ngo/death.avro\"\n",
    "featuresPath=\"gs://bigdataween-ngo/dataproc-results/features.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features extracted in the Extract-features notebook\n",
    "features = spark.read.parquet(featuresPath)\n",
    "# Load the labels\n",
    "labels = spark.read.format(\"avro\").load(labelsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the features with the labels for training\n",
    "data = features.join(labels.withColumn('label', lit(1)), on=\"person_id\", how=\"left\").fillna({\"label\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "trainData, testData = data.randomSplit([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Naive Bayes classifier and train it\n",
    "clf = NaiveBayes(labelCol=\"label\", featuresCol=\"featuresBinomial\", modelType=\"bernoulli\")\n",
    "mlModel = clf.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the predictions and measure false positives and true positives\n",
    "predictions = mlModel.transform(testData)\n",
    "fp = predictions.where( (col(\"label\")==0) & (col(\"prediction\") == 1.0) ).count()    \n",
    "tp = predictions.where( (col(\"label\")==1) & (col(\"prediction\") == 1.0) ).count()\n",
    "print(\"FP = {} - TP ={}\".format(fp,tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}