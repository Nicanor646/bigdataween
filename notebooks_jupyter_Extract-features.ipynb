{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import array, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc = SparkContext()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the paths to the data\n",
    "conceptsFilename=\"gs://bigdataween-ngo/concept_ids.avro\"\n",
    "dataFilename=\"gs://bigdataween-ngo/export-features/export_features_*.avro\"\n",
    "resultFilename=\"gs://bigdataween-ngo/dataproc-results/features.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = spark.read.format(\"avro\").load(dataFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- person_id: long (nullable = true)\n",
      " |-- gender_type: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- age_range_type: long (nullable = true)\n",
      " |-- concept_ids: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the schema\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+---+--------------+--------------------+\n",
      "|person_id|gender_type|age|age_range_type|         concept_ids|\n",
      "+---------+-----------+---+--------------+--------------------+\n",
      "|   798884|          2| 88|            15|[194133, 30437, 3...|\n",
      "|  1754384|          2| 78|            13|[372610, 201826, ...|\n",
      "|  2256256|          1| 57|             9|[31317, 436701, 1...|\n",
      "|  1419579|          1| 90|            15|[197381, 312437, ...|\n",
      "|   767247|          2| 97|            15|[433168, 375545, ...|\n",
      "|   712219|          1| 66|            11|[4044351, 192731,...|\n",
      "|   753844|          2| 99|            15|[134668, 1550776,...|\n",
      "|  1799283|          2| 97|            15|[40483189, 432271...|\n",
      "|  1137790|          2|104|            15|[439777, 4002650,...|\n",
      "|   479207|          2| 90|            15|[443076, 75036, 3...|\n",
      "+---------+-----------+---+--------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show 10 rows\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the concepts\n",
    "conceptsData = spark.read.format(\"avro\").load(conceptsFilename)\n",
    "# Turn the column of strings into vectors of a single string per row\n",
    "codeIdsArray=conceptsData.select(array(\"concept_ids\").alias(\"concept_ids\")).fillna(\"0\")\n",
    "\n",
    "# create the count vectorizer\n",
    "cvConceptsCounts = CountVectorizer(inputCol=\"concept_ids\", outputCol=\"concept_ids_counts_vec\").fit(codeIdsArray)\n",
    "# Create the binary (one-hot) count vectorizer ()\n",
    "cvConcepts = CountVectorizer(inputCol=\"concept_ids\", outputCol=\"concept_ids_bool_vec\", binary=True).fit(codeIdsArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the one-hot encoder for age ranges\n",
    "age_ranges = spark.createDataFrame(range(16),IntegerType()).withColumnRenamed('value','age_range_type')\n",
    "ageRangeEncoder = OneHotEncoderEstimator(inputCols=['age_range_type'], outputCols=['age_range_vec'], handleInvalid='keep').fit(age_ranges)\n",
    "\n",
    "# Create the one-hot encoder for gender\n",
    "genders = spark.createDataFrame([(0,'U'), (1,'M'), (2,'F')],['gender_type', 'gender'])\n",
    "genderEncoder = OneHotEncoderEstimator(inputCols=['gender_type'], outputCols=['gender_vec'], handleInvalid='keep').fit(genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Vector assemblers (puts together all the vectors and values)\n",
    "vaBinomial = VectorAssembler(inputCols=['age_range_vec', 'gender_vec',  'concept_ids_bool_vec'],\n",
    "    outputCol='featuresBinomial', handleInvalid='keep')\n",
    "\n",
    "vaMultinomial= VectorAssembler(inputCols=['age', 'gender_vec', 'concept_ids_counts_vec'],\n",
    "    outputCol='featuresMultinomial', handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming data to features\n",
      "root\n",
      " |-- person_id: long (nullable = true)\n",
      " |-- gender_type: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- age_range_type: long (nullable = true)\n",
      " |-- concept_ids: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- age_range_vec: vector (nullable = true)\n",
      " |-- gender_vec: vector (nullable = true)\n",
      " |-- concept_ids_counts_vec: vector (nullable = true)\n",
      " |-- concept_ids_bool_vec: vector (nullable = true)\n",
      " |-- featuresBinomial: vector (nullable = true)\n",
      " |-- featuresMultinomial: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply all of the transforms\n",
    "print(\"Transforming data to features\")\n",
    "data_vector = data\n",
    "for transformer in [ageRangeEncoder,  genderEncoder, cvConceptsCounts,cvConcepts,vaBinomial,vaMultinomial]:\n",
    "    data_vector = transformer.transform(data_vector)\n",
    "\n",
    "data_vector.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing transformed data\n"
     ]
    }
   ],
   "source": [
    "# Write the transformed data (this is the instruction that actually starts processing data)\n",
    "print(\"Writing transformed data\")\n",
    "resultFilename=\"gs://bigdataween-ngo/dataproc-results/features2.parquet\"\n",
    "data_vector.select(\"person_id\",\"featuresBinomial\",\"featuresMultinomial\")\\\n",
    "           .write.parquet(resultFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}